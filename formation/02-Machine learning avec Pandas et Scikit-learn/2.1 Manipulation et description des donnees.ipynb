{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulation des données et premières statistiques\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 La librairie `Pandas`\n",
    "`Pandas` est une bibliothèque écrite pour le langage de programmation Python permettant la manipulation et l'analyse des données. Nous allons ici détailler l'utilisation des deux structures de base de ce package que sont les `Series` et `DataFrame`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Les objets `Series`\n",
    "On charge la libairie `Pandas` (souvent abregé `pd` lors de l'import)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La première structure de Pandas est l'objet `Series`.\n",
    "\n",
    "On peut créer une `Series` à partir d'une `list`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie = pd.Series([8, 18, 10, 15])\n",
    "serie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Les objets `DataFrame`\n",
    "\n",
    "On peut créer un `DataFrame` à partir d'une `list` ou d'un `numpy.array`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(\n",
    "    [\n",
    "        [8, 0],\n",
    "        [18, 7],\n",
    "        [\n",
    "            10,\n",
    "            1,\n",
    "        ],\n",
    "        [14, 3],\n",
    "    ]\n",
    ")\n",
    "df = pd.DataFrame(arr)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Créer une nouvelle colonne à partir d'une liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[2] = [\"Paris\", \"Lille\", \"Montpellier\", \"Toulouse\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renommer les colonnes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [\"temperature\", \"precipitation\", \"ville\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut également définir une colonne comme index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index(\"ville\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manipulation des colonnes\n",
    "\n",
    "Sur un Dataframe, on peut:\n",
    "- selectionner  une colonne avec :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"temperature\"]  # ou df.temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- construire de nouvelles colonnes à partir de colonnes existantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"mon_calcul\"] = 2 * df.temperature + df.precipitation\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Manipulation des lignes\n",
    "On extrait une ligne par son index en utilisant :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[\"Toulouse\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On extrait une ligne par sa position en utilisant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On extrait des valeurs à partir de listes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[[\"Toulouse\", \"Paris\"], [\"precipitation\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On extrait des valeurs à partir des indexs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1:3, 1:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Les outils pour importer les données\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans le cadre de ce Notebook, pour chaque jeu de données trop volumineux, nous conservons une version avec un extrait des données dans ce répertoire et un lien vers un autre site avec les données complètes (le code pour récupérer ces fichiers volumineux est présent sous forme de commentaire).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importer des données externes\n",
    "L’une des forces de `Pandas` est l’importation et l’exportation des données. \n",
    "\n",
    "Cette libairie possède un ensemble de fonctions très larges pour charger des données en mémoire et les exporter dans divers formats. Nous allons nous concentrer ici sur le chargement d'un fichier `.csv`, mais il est tout à fait possible de charger des fichiers `.xlsx` ou même `sql`.\n",
    "\n",
    "#### Importer un fichier csv\n",
    "La fonction [*read_csv()*](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html) est une fonction avec un grand nombre d'arguments, nous ne nous concentrons ici que sur les plus importants.\n",
    "\n",
    "Dans le cas d’un fichier csv classique, un seul paramètre est nécessaire. Il s’agit du chemin vers le fichier. Votre fichier peut se trouver directement sur votre machine mais aussi en ligne. Dans ce cas, il vous suffit de rentrer une adresse web. \n",
    "\n",
    "D’autres arguments peuvent vous être utiles lors du traitement d'un fichier `.csv` :\n",
    "\n",
    "- `delimiter` : afin de donner le format des séparateurs entre valeurs dans le fichier. Utile dans le cas d’un csv avec des séparateurs points-virgules,\n",
    "- `decimal` : afin de spécifier le séparateur décimal. Utile dans le cas d’un csv avec des séparateurs décimaux utilisant une virgule,\n",
    "- `index_col` : afin de spécifier la position de la colonne servant d’index dans le DataFrame créé (attention les colonnes sont toujours indexées à 0),\n",
    "- `header` : afin de dire si le titre de la colonne se trouve dans la première ligne. Si ce n’est pas le cas, on peut utiliser le paramètre names afin de fournir une liste avec le nom des colonnes pour le DataFrame,\n",
    "- `dtypes` : dans le cas de gros jeux de données, il peut être intéressant de fournir une liste de types de colonnes ou un dictionnaire afin d’éviter à Python d’avoir à les deviner (ce qui vous évitera certains warnings),\n",
    "- d'autres arguments, notamment sur le traitement des données manquantes, sur la transformation des dates, sur le codage des chaînes de caractères sont aussi disponibles.\n",
    "\n",
    "Pour notre exemple, nous souhaitons récupérer les données des logements AirBnB de Paris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import de la première colonne du fichier\n",
    "listing = pd.read_csv(\"../data/listing_extrait.csv\", index_col=0)\n",
    "\n",
    "# Import du fichier complet\n",
    "# listing = pd.read_csv(\"https://www.stat4decision.com/listing.csv.gz\", index_col=0)\n",
    "listing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remarque:** Pour importer un fichier csv très volumineux, il existe deux solutions:\n",
    "- l'argument `chunksize` permet de lire des morceaux d'un fichier de manière itérative\n",
    "- la librairie [**Dask**](https://www.dask.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Décrire et transformer des colonnes\n",
    "### 2.1 Décrire la structure de vos données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- On charge un nouveau jeu de données sur les salaires des employés de la ville de Boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = pd.read_csv(\"../data/employee-earnings-report-2017.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quel que soit le type de structure que vous utilisez (`numpy.array`, `pandas.Series` ou `pandas.DataFrame`), on utilise généralement une propriété de ces objets : la propriété `shape`. Celle-ci renvoie toujours un `tuple`, qui a autant d’éléments que de dimensions dans vos données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut on obtenir le nom des colonnes en utilisant la propriété `columns`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette information est importante mais reste peu détaillée. Lorsqu’on travaille sur un `DataFrame`, on va chercher à avoir beaucoup plus de détails. Pour cela, nous allons utiliser la méthode `info`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une autre étape importante est l’étude de l’aspect de notre `DataFrame`, on peut par exemple afficher les premières lignes du jeu de données avec la méthode `head`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on modifie les colonnes numériques\n",
    "# (nous repalerons de problème de type plus tard)\n",
    "for col in boston.columns:\n",
    "    if boston[col].dtype == object:\n",
    "        boston[col] = pd.to_numeric(\n",
    "            boston[col].str.replace(r\"\\(.*\\)\", \"\").str.replace(\",\", \"\").str.strip(\"$\"),\n",
    "            errors=\"ignore\",\n",
    "        )\n",
    "boston.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistiques pour données quantitatives\n",
    "Lorsqu'on calcule des statistiques descriptives spécifiques aux données quantitatives sur un `DataFrame` complet, `Pandas` n’affiche des résultats que pour les variables quantitatives (sans message d’erreur pour les colonnes non quantitatives).\n",
    "\n",
    "Statistiques descriptives de base:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moyenne\n",
    "boston.mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De manière similaire, on dispose des fonctions suivantes:\n",
    "- variance : `.var()`\n",
    "- écart-type: `.std()`\n",
    "- médiane : `.median()`\n",
    "\n",
    "Une autre fonction intéressante est la méthode `.describe()` qui affiche un certain nombre de statistiques pour les variables quantitatives (elle ne fait que cela par défaut mais nous verrons plus loin qu’elle peut s’appliquer aux variables qualitatives)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut égalisement visualiser nos données. `Pandas` hérite de nombreuses fonctions de `matplotlib` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston.hist(figsize=(10, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistiques pour données qualitatives\n",
    "Les statistiques descriptives pour des variables qualitatives sont très différentes de celles pour des variables quantitatives. Ainsi, on s’intéresse généralement au mode et à la fréquence des modalités de la variable:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nombre de modalités\n",
    "boston[\"DEPARTMENT NAME\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# liste de modalités\n",
    "boston[\"DEPARTMENT NAME\"].unique()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# liste et fréquence d’apparition des modalités\n",
    "boston[\"DEPARTMENT NAME\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston[\"DEPARTMENT NAME\"].value_counts().head(10).plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Remarque**: la méthode `.value_counts()` possède un certain nombre de paramètres pour inclure les données manquantes, normaliser les résultats, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Quelles transformations pour les colonnes de vos données ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Votre objectif en tant que data scientist est d’extraire le plus d’information possible de ces données. Pour cela, il va falloir les mettre en forme de manière intelligente. \n",
    "\n",
    "Nous allons étudier différentes transformations souvent nécessaires pour travailler sur des données :\n",
    "\n",
    "- 1. les changements de types,\n",
    "- 2. la déduplication,\n",
    "- 3. le traitement des données manquantes,\n",
    "- 4. le traitement des colonnes avec des données qualitatives,\n",
    "- 5. les transformations numériques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Les changements de types\n",
    "\n",
    "Le typage des colonnes d’un DataFrame ou d’un array est très important pour tous les traitements en data science.\n",
    "\n",
    "Nous nous concentrons ici sur les structures en DataFrame de Pandas. Pandas va automatiquement inférer les types si vous ne lui avez pas spécifié de type à l’importation des données ou à la création du DataFrame.\n",
    "\n",
    "Par défaut, `Pandas` va utiliser 4 types principaux :\n",
    "- les entiers (`int32` ou `int64`),\n",
    "- les nombres décimaux (`float32` ou `float64`),\n",
    "- les booléen (`bool`) \n",
    "- les `Object` qui  acceptent un melange de différents types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La base de données listing de AirBnB est obtenue par scrapping web et certaines informations ne peuvent pas être traitées directement. En effet, lorsqu’on affiche les\n",
    "informations sur les colonnes, on voit que la colonne price est typée en `Object` alors qu’il s’agit de valeurs décimales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing[\"price\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour nous débarrasser du `$` en première position :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remplace tous les $\n",
    "listing[\"price\"].str.replace(\"$\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il reste deux étapes à réaliser : éliminer les virgules et transformer la variable en\n",
    "variable numérique :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing[\"price\"] = pd.to_numeric(\n",
    "    listing[\"price\"].str.replace(\"$\", \"\").str.replace(\",\", \"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing[\"price\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons donc réussi à modifier notre colonne."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si on étudie la colonne \"instant_bookable\", on veut pouvoir prendre en compte cette colonne pour la passer en booléen :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing[\"instant_bookable\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing[\"instant_bookable_bool\"] = listing[\"instant_bookable\"].replace(\n",
    "    {\"f\": False, \"t\": True}\n",
    ")\n",
    "listing.instant_bookable_bool.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Il existe de nombreux cas de nettoyages de données basées sur des erreurs de\n",
    "typage. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 La gestion des duplications de lignes\n",
    "\n",
    "Il arrive souvent dans des données que des lignes soient dupliquées par erreur ou que vous désiriez vérifier la duplication de certaines lignes.\n",
    "\n",
    "`Pandas` possède deux méthodes pour traiter ce type de données : `duplicated()` et `drop_duplicated()`.\n",
    "\n",
    "Si nous voulons vérifier si des lignes sont dupliquées dans le DataFrame sur les employés de la ville de Boston, il nous suffit de faire :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il s’avère qu’il n’y a aucune duplication. Nous aurions pu nous concentrer uniquement\n",
    "sur le nom, le département et le titre des employés :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"NAME\", \"DEPARTMENT NAME\", \"TITLE\"]\n",
    "boston.duplicated(cols).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on a donc quatre éléments dupliqués, on peut maintenant les visualiser :\n",
    "\n",
    "boston[boston.duplicated(cols, keep=False)].sort_values(by=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons maintenant nous débarrasser des duplications, on utilisera pour cela :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_no_dup = boston.drop_duplicates(\n",
    "    [\"NAME\", \"DEPARTMENT NAME\", \"TITLE\"], keep=\"first\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Dans ce cas, on garde le premier. On peut demander à garder le dernier (last) et\n",
    "on utilisera des tris afin d’ordonner les résultats pour se débarrasser des duplications\n",
    "non pertinentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 Le traitement des données manquantes\n",
    "La gestion des données manquantes est un domaine de la data science à part entière. Leur traitement nécessite une réflexion bien au-delà de quelques lignes de codes.\n",
    "\n",
    "Dans tous vos projets data science, vous serez confrontés à des données manquantes, deux startégies peuvent pricipalement être adoptées:\n",
    "- supprimer les données manquantes (le plus facile s'il y en a peu),\n",
    "- attribuer des valeurs à ces données manquantes, on parle de complétion. Nous présenterons quelques startégies pour compléter les valeurs manquantes.\n",
    "\n",
    "**Remarque**: Lorsque vous importez des données avec `Pandas`, celui-ci va automatiquement remplacer les données manquantes par des codes `nan`. `Pandas` utilise le type `np.nan` de `Numpy`. Lors de l'application de fonctions sur une série (ex: la moyenne `.mean()`), les données manquantes sont ignorées. Cela évite des bugs mais cela peut-être trompeur également. On n'a pas forcément conscience qu'il nous manque des données à l'usage car on ne reçoit pas de message d'erreur\n",
    "\n",
    "#### La suppression des données manquantes\n",
    "L’approche la plus simple pour traiter des données manquantes est de supprimer les observations comportant des données manquantes.\n",
    "\n",
    "`Pandas` comporte de nombreuses méthodes pour cela. Si nous prenons les données sur les salaires des employés de la ville de Boston, nous pouvons utiliser :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# la table globale\n",
    "boston.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# la table lorsqu’on retire les lignes avec données manquantes\n",
    "boston.dropna().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# la table lorsqu’on retire les colonnes avec des données manquantes\n",
    "boston.dropna(axis=1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit que dans cette table de nombreuses données manquantes existent surtout sur huit colonnes. Quatre colonnes sont complètes.\n",
    "\n",
    "#### La complétion par la moyenne, ou la médiane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il existe deux moyens de compléter des données par la moyenne ou par la médiane.\n",
    "\n",
    "Un premier en utilisant `Pandas` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour la moyenne\n",
    "boston.INJURED = boston.INJURED.fillna(boston.INJURED.mean(numeric_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La librairie `Scikit-Learn` permet aussi de faire des remplacements par la moyenne ou la médiane :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# on crée un objet de cette classe avec la stratégie d’imputation comme\n",
    "# paramètre\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "# on construit un nouveau jeu de données en appliquant la méthode\n",
    "# .fit_transform()\n",
    "boston_imputee = imputer.fit_transform(boston.select_dtypes(np.number))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.4 Le traitement des colonnes avec des données qualitatives\n",
    "Les données qualitatives sont extrêmement présentes dans les données. Dès que vous travaillez sur des données socio-démographiques sur des individus, vous allez rencontrer des données qualitatives. Le traitement des données qualitatives est souvent négligé dans les ouvrages de traitement de la donnée. Il est donc primordial de bien expliquer le traitement qu’elles requièrent.\n",
    "\n",
    "#### Le type categorical\n",
    "Les données qualitatives sont des valeurs textuelles par défaut. Pandas propose un type spécifique pour traiter ce type de données. Le type categorical permet d’optimiser le traitement de ce type de données.\n",
    "\n",
    "Il permet de créer et de transformer des données de ce type. Vous avez importé des données avec des variables qualitatives, `Pandas` va automatiquement les considérer comme du type `Object`. Vous pourrez le voir en utilisant la propriété `.dtype`.\n",
    "Si vous désirez transformer ce type en un type categorical, vous pouvez utiliser la fonction `pd.Categorical()` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_quali = pd.Categorical([\"Boston\", \"Paris\", \"Londres\", \"Paris\", \"Boston\"])\n",
    "var_quali.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### La transformation des données\n",
    "Pour traiter des données qualitatives, il faudra les transformer. \n",
    "\n",
    "En effet, les algorithmes que vous aurez à utiliser sont basés sur des données numériques et donc des variables quantitatives.\n",
    "\n",
    "Si vous travaillez sur des données nominales, il va falloir transformer les variables en indicatrices. C’est-à-dire que vous allez obtenir une colonne pour chaque modalité de votre variable qualitative.\n",
    "\n",
    "Cette approche peut être appliquée avec deux packages que nous utilisons souvent : `Pandas` et `Scikit-Learn`.\n",
    "\n",
    "Dans le cadre de nos données sur les logements AirBnB, nous avons plusieurs variables qualitatives, notamment roomtype qui a trois modalités :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing[\"room_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Approche `Pandas` avec `get_dummies()` qui créé un nouveau `DataFrame` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_room_type = pd.get_dummies(listing[\"room_type\"])\n",
    "frame_room_type.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Approche `Scikit-Learn` avec `OneHotEncoder()` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on importe la classe\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# on crée un objet de la classe OneHotEncoder\n",
    "encode = OneHotEncoder(sparse_output=False)\n",
    "# on l'applique directement sur la colonnes initiale\n",
    "array_out = encode.fit_transform(np.array(listing[\"room_type\"]).reshape(-1, 1))\n",
    "# on transforme la sortie en DataFrame\n",
    "pd.DataFrame(array_out, columns=listing[\"room_type\"].unique()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.5 Les transformations numériques\n",
    "\n",
    "Lorsque vous travaillez sur des données, un certain nombre de transformations de base sont nécessaires. Deux librairies pourront être utiles pour ce type de transformations : `Scikit-Learn`, `Pandas`.\n",
    "\n",
    "- Avec `Pandas`, la plupart des transformations se font en faisant les calculs directement en utilisant les fonctions universelles de Pandas.\n",
    "\n",
    "- Avec `Scikit-Learn`, l’approche est légèrement différente. Dans ce cas, on utilise des classes permettant de transformer les données.\n",
    "\n",
    "Nous utiliserons les données sur les employés de la ville de Boston desquelles nous extrayons les colonnes numériques :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_num = boston.select_dtypes(include=[np.number])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Centrer et réduire les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avec Pandas pour centrer et réduire\n",
    "boston_std = boston_num.apply(lambda x: (x - x.mean()) / x.std())\n",
    "boston_std.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avec Scikit-Learn, on utilisera la classe StandardScaler :\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "rescaled = scaler.fit_transform(boston_num)\n",
    "pd.DataFrame(rescaled, index=boston_num.index, columns=boston_num.columns).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changer d’échelle\n",
    "\n",
    "On utilise pour passer à une échelle 0-100 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avec Pandas\n",
    "boston_0_100 = boston_num.apply(lambda x: (x - x.min()) / (x.max() - x.min()) * 100)\n",
    "boston_0_100.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avec Scikit-Learn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "minmaxscaler = MinMaxScaler((0, 100))\n",
    "boston_0_100 = minmaxscaler.fit_transform(boston_num)\n",
    "boston_0_100 = pd.DataFrame(\n",
    "    boston_0_100, index=boston_num.index, columns=boston_num.columns\n",
    ")\n",
    "boston_0_100.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Utilisation du groupby pour décrire des données\n",
    "\n",
    "La méthode `groupby` est une méthode qui permet de construire un objet à partir d’un `DataFrame`. Cet objet de type `DataFrameGroupBy` sépare les données en fonction des modalités d’une ou de plusieurs variables qualitatives. On obtiendra ainsi de manière quasi-immédiate des indicateurs par modalités. \n",
    "\n",
    "De nombreuses méthodes sont disponibles sur ces objets `DataFrameGroupBy` afin de maximiser la simplicité de manipulation de données.\n",
    "Généralement, on suppose que le `groupby` est basé sur trois étapes : séparation, application et combinaison (voir [la documentation](https://pandas.pydata.org/docs/user_guide/groupby.html) pour plus d'informations).\n",
    "\n",
    "Par exemple, sur les données AirBnB, on peut regrouper les lignes par type de chambres :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_group_room = listing.groupby(\"room_type\")\n",
    "listing_group_room[\"price\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis on calcule la moyenne, et on rassemble les résultats dans un nouvel objet. On affiche donc dans un objet `Series` les prix moyens par type de chambre. On voit ici qu’on a utilisé la méthode `mean` des objets `DataFrameGroupBy`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `apply` : une méthode importante pour manipuler vos `DataFrameGroupBy`\n",
    "\n",
    "La méthode `apply` permet d’appliquer n’importe quelle fonction sur vos données.\n",
    "\n",
    "Si par exemple, vous désirez calculer l’écart salarial au sein de chaque département sur les données des salariés de la ville de Boston, vous allez devoir utiliser la différence entre le maximum et le minimum. Il n’existe pas de fonction universelle. \n",
    "\n",
    "Nous allons donc utiliser un `groupby` et un `apply` sur une seule ligne pour réaliser cette opération:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_salaires_dep = boston.groupby(\"DEPARTMENT NAME\")[\"TOTAL EARNINGS\"].apply(\n",
    "    lambda x: x.max() - x.min()\n",
    ")\n",
    "diff_salaires_dep.sort_values(ascending=False).head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
