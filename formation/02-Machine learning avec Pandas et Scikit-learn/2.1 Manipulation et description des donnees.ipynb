{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulation des données et premières statistiques\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 La librairie Pandas\n",
    "Pandas est une bibliothèque écrite pour le langage de programmation Python permettant la manipulation et l'analyse des données. Nous allons ici détailler l'utilisation des deux structures de base de ce package que sont les Series et DataFrame.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Les objets Series de Pandas\n",
    "On charge le package Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La première structure de Pandas est l'objet **Series**.\n",
    "\n",
    "On peut créer une Series à partir d'une liste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste = pd.Series([8, 18, 10, 15])\n",
    "liste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Les objets DataFrame de Pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut créer un DataFrame à partir d'une liste ou array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste = np.array([[ 8,  0], \n",
    "         [18,  7],\n",
    "         [10,  1,],\n",
    "         [14,  3]])\n",
    "df = pd.DataFrame(liste)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Créer une nouvelle colonne à partir d'une liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[2]=[\"Paris\", \"Lille\",\"Montpellier\",\"Toulouse\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renommer les colonnes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['temperature' , 'precipitation', 'ville']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut également définir une colonne comme index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index(\"ville\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manipulation des colonnes\n",
    "\n",
    "Sur un Dataframe, on peut:\n",
    "- selectionner  une colonne avec :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['temperature'] # ou df.temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- construire de nouvelles colonnes à partir de colonnes existantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"mon_calcul\"] = 2 * df.temperature + df.precipitation\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Manipulation des lignes\n",
    "On extrait une ligne par son index en utilisant :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[\"Toulouse\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On extrait une ligne par sa position en utilisant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On extrait des valeurs à partir de listes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[[\"Toulouse\",\"Paris\"],[\"precipitation\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On extrait des valeurs à partir des indexs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1:3,1:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Les outils pour importer les données\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans le cadre de ce Notebook, pour chaque jeu de données trop volumineux, nous conservons une version avec un extrait des données dans ce répertoire et un lien vers un autre site avec les données complètes (le code pour récupérer ces fichiers volumineux est présent sous forme de commentaire.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importer des données externes\n",
    "L’une des forces de Pandas est l’importation et l’exportation des données. \n",
    "\n",
    "Ce package possède un ensemble de fonctions très large pour charger des données en mémoire et les exporter dans divers formats. Nous allons développer de nombreux exemples.\n",
    "#### Importer un fichier csv\n",
    "La fonction *read_csv()* de Pandas est une fonction avec un nombre de paramètres impressionnant, nous ne nous concentrons ici que sur quelques-uns qui sont importants.\n",
    "\n",
    "Dans le cas d’un fichier csv classique, un seul paramètre est nécessaire. Il s’agit du chemin vers le fichier. Votre fichier peut se trouver directement sur votre machine mais aussi en ligne. Dans ce cas, il vous suffit de rentrer une adresse web. \n",
    "\n",
    "D’autres paramètres pourront vous être utiles lors du traitement de csv :\n",
    "\n",
    "- *delimiter* : afin de donner le format des séparateurs entre valeurs dans le fichier. Utile dans le cas d’un csv avec des séparateurs points-virgules,\n",
    "- *decimal* : afin de spécifier le séparateur décimal. Utile dans le cas d’un csv avec des séparateurs décimaux utilisant une virgule,\n",
    "- *index_col* : afin de spécifier la position de la colonne servant d’index dans le DataFrame créé (attention les colonnes sont toujours indexées à 0),\n",
    "- *header* : afin de dire si le titre de la colonne se trouve dans la première ligne. Si ce n’est pas le cas, on peut utiliser le paramètre names afin de fournir une liste avec le nom des colonnes pour le DataFrame,\n",
    "- *dtypes* : dans le cas de gros jeux de données, il peut être intéressant de fournir une liste de types de colonnes ou un dictionnaire afin d’éviter à Python d’avoir à les deviner (ce qui vous évitera certains warnings),\n",
    "- de nombreux autres paramètres, notamment sur le traitement des données manquantes, sur la transformation des dates, sur le codage des chaînes de caractères…\n",
    "\n",
    "On utilise *pd.read_csv()* pour lire un fichier csv\n",
    "\n",
    "Dans ce cas, on va récupérer les données des logements AirBnB de Paris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import d'un extrait\n",
    "listing=pd.read_csv(\"../data/listing_extrait.csv\", index_col=0)\n",
    "# Import du fichier complet\n",
    "#listing=pd.read_csv(\"https://www.stat4decision.com/listing.csv.gz\", index_col=0)\n",
    "listing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remarque** Pour importer un fichier csv très volumineux, il existe deux solutions:\n",
    "- l'option 'chunksize' de read_csv qui permet de lire des morceaux d'un fichier de manière itérative\n",
    "- la librairie **Dask**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importer un fichier Excel\n",
    "\n",
    "Microsoft Excel reste l’un des outils de base pour traiter de la donnée. Dans la plupart des projets de data science, vous serez amené à croiser un fichier Excel, que ce soit pour stocker des données ou pour stocker des références ou des informations\n",
    "annexes.\n",
    "\n",
    "Pandas possède des outils pour importer des données en Excel sans avoir à passer\n",
    "par une transformation en csv (souvent fastidieuse si vous avez des classeurs avec de\n",
    "nombreuses feuilles)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### pd.read_excel() :\n",
    "\n",
    "Cette approche ressemble à l’importation en csv. Pour récupérer le fichier Excel, il faut connaître le nom ou la position de la feuille qui nous intéresse :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on peut ajouter le nom de la feuille\n",
    "frame_credit=pd.read_excel(\"../data/credit.xlsx\", sheet_name=\"donnees\")\n",
    "frame_credit.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on peut utiliser uniquement certaines colonnes\n",
    "frame_credit_af=pd.read_excel(\"../data/credit.xlsx\", sheet_name=\"donnees\", usecols=\"A:E\")\n",
    "frame_credit.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importer une table issue d’une base de données SQL\n",
    "\n",
    "Le langage SQL  est un langage central de la science des données. La majorité des\n",
    "bases de données relationnelles peuvent être requêtées en utilisant le langage SQL.\n",
    "C’est d’ailleurs aujourd’hui l’un des trois langages les plus utilisés par le data scientist\n",
    "(après Python et R). SQL va vous permettre d’extraire des tables de données qui\n",
    "pourront ensuite être chargées en mémoire dans des DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour passer de la base SQL à Python, il faut donc un connecteur permettant de\n",
    "se connecter à la base et de faire des requêtes directement dessus. Un package\n",
    "central de Python est très utile dans ce but : c’est SQLalchemy qui a aujourd’hui\n",
    "remplacé les nombreux packages spécifiques qui pouvaient exister afin de requêter\n",
    "des bases de données SQL en fonction du type de base : MySQL, PostgreSQL,\n",
    "SQLlite… SQLalchemy a l’avantage de fournir une seule approche.\n",
    "\n",
    "On va utliser :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///../data/salaries.sqlite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on peut vérifier le nom des tables\n",
    "with engine.connect().execution_options(stream_results=True) as ma_con:\n",
    "    tables_in_db = pd.read_sql('SELECT name FROM sqlite_master WHERE type=\"table\";', ma_con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables_in_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on peut charger les données\n",
    "with engine.connect().execution_options(stream_results=True) as ma_con:\n",
    "    frame_sql = pd.read_sql(\"SELECT * FROM Salaries\", ma_con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_sql.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Décrire et transformer des colonnes\n",
    "### 2.1 Décrire la structure de vos données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- On charge un nouveau jeu de données sur les salaires des employés de la ville de Boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston=pd.read_csv(\"../data/employee-earnings-report-2017.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quel que soit le type de structure que vous utilisez ; les arrays, les Series ou\n",
    "les DataFrame, on utilise généralement une propriété de ces objets : la propriété\n",
    "    .shape. Celle-ci renvoie toujours un tuple, qui aura autant d’éléments que de dimensions\n",
    "dans vos données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut on obtenir le nom des colonnes en utilisant :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette information est importante mais reste peu détaillée. Lorsqu’on travaille sur\n",
    "un DataFrame, on va chercher à avoir beaucoup plus de détails. Pour cela, nous allons\n",
    "utiliser la méthode .info(). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une autre étape importante est l’étude de l’aspect de notre DataFrame, on peut\n",
    "par exemple afficher les premières lignes du jeu de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on modifie les colonnes numériques \n",
    "# (nous repalerons de problème de type plus tard)\n",
    "for col in boston.columns :\n",
    "    if boston[col].dtype==object :\n",
    "        boston[col]=pd.to_numeric(boston[col].str.replace(r\"\\(.*\\)\",\"\")\\\n",
    "                                  .str.replace(\",\",\"\").str.strip(\"$\"),\n",
    "                                  errors='ignore')\n",
    "boston.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistiques pour données quantitatives\n",
    "Lorsqu'on calcule des statistiques descriptives spécifiques aux données quantitatives sur un DataFrame complet, Pandas n’affiche des résultats que pour les variables quantitatives (sans message d’erreur pour les colonnes non quantitatives).\n",
    "\n",
    "Statistiques descriptives de base\n",
    "Quelques méthodes statistiques universelles de Pandas :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moyenne\n",
    "boston.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De manière similaire, on dispose des fonctions suivantes:\n",
    "- variance : .var()\n",
    "- écart-type: .std()\n",
    "- médiane : .median()\n",
    "\n",
    "Une autre fonction intéressante est la méthode .describe() qui affiche un certain nombre de statistiques pour les variables quantitatives (elle ne fait que cela par défaut mais nous verrons plus loin qu’elle peut s’appliquer aux variables qualitatives)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut égalisement visualiser nos données. Pandas hérite de nombreuses fonctions de matplotlib :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston.hist(figsize=(10,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistiques pour données qualitatives\n",
    "Les statistiques descriptives pour des variables qualitatives sont très différentes de celles pour des variables quantitatives. Ainsi, on s’intéresse généralement au mode et à la fréquence des modalités de la variable:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nombre de modalités\n",
    "boston['DEPARTMENT NAME'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# liste de modalités\n",
    "boston['DEPARTMENT NAME'].unique()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# liste et fréquence d’apparition des modalités\n",
    "boston[\"DEPARTMENT NAME\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston[\"DEPARTMENT NAME\"].value_counts().head(10).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Remarque**: la méthode .value_counts() possède un certain nombre de paramètres pour inclure les données manquantes, normaliser les résultats..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Quelles transformations pour les colonnes de vos données ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Votre objectif en tant que data scientist est d’extraire le plus d’information possible de ces données. Pour cela, il va falloir les mettre en forme de manière intelligente. \n",
    "\n",
    "Nous allons étudier différentes transformations souvent nécessaires pour travailler sur des données :\n",
    "\n",
    "- 1. les changements de types,\n",
    "- 2. la déduplication,\n",
    "- 3. le traitement des données manquantes,\n",
    "- 4. le traitement des colonnes avec des données qualitatives,\n",
    "- 5. les transformations numériques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Les changements de types\n",
    "\n",
    "Le typage des colonnes d’un DataFrame ou d’un array est très important pour tous les traitements en data science.\n",
    "\n",
    "Nous nous concentrons ici sur les structures en DataFrame de Pandas. Pandas va automatiquement inférer les types si vous ne lui avez pas spécifié de type à l’importation\n",
    "des données ou à la création du DataFrame.\n",
    "\n",
    "Par défaut, Pandas va utiliser trois types principaux :\n",
    "- les entiers (int en 32 ou en 64 bits),\n",
    "- les nombres décimaux (float en 32 ou 64 bits),\n",
    "- les objets object qui rassemblent la plupart des autres types.\n",
    "\n",
    "On trouvera aussi des booléens et tous les types définis par NumPy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La base de données listing de AirBnB est obtenue par scrapping web et certaines informations ne peuvent pas être traitées directement. En effet, lorsqu’on affiche les\n",
    "informations sur les colonnes, on voit que la colonne price est typée en Object alors qu’il s’agit de valeurs décimales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing[\"price\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour nous débarrasser du $ en première position :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remplace tous les $\n",
    "listing[\"price\"].str.replace(\"$\",\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il reste deux étapes à réaliser : éliminer les virgules et transformer la variable en\n",
    "variable numérique :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing[\"price\"]= pd.to_numeric(listing[\"price\"].str.replace(\"$\",\"\").str.replace(\",\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing[\"price\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons donc réussi à modifier notre colonne."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si on étudie la colonne \"instant_bookable\", on veut pouvoir prendre en compte cette colonne pour la passer en booléen :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing[\"instant_bookable\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing[\"instant_bookable_bool\"]= listing[\"instant_bookable\"].replace({\"f\" : False,\"t\" : True})\n",
    "listing.instant_bookable_bool.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Il existe de nombreux cas de nettoyages de données basées sur des erreurs de\n",
    "typage. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 La gestion des duplications de lignes\n",
    "\n",
    "Il arrive souvent dans des données que des lignes soient dupliquées par erreur ou que vous désiriez vérifier la duplication de certaines lignes.\n",
    "\n",
    "Pandas possède deux outils pour traiter ce type de données : duplicated() et drop_duplicated().\n",
    "\n",
    "Si nous voulons vérifier si des lignes sont dupliquées dans le DataFrame sur les employés de la ville de Boston, il nous suffit de faire :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il s’avère qu’il n’y a aucune duplication. Nous aurions pu nous concentrer uniquement\n",
    "sur le nom, le département et le titre des employés :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['NAME','DEPARTMENT NAME','TITLE']\n",
    "boston.duplicated(cols).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on a donc quatre éléments dupliqués, on peut maintenant les visualiser :\n",
    "\n",
    "boston[boston.duplicated(cols, keep=False)].sort_values(by= cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons maintenant nous débarrasser des duplications, on utilisera pour cela :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_no_dup=boston.drop_duplicates(['NAME','DEPARTMENT NAME','TITLE'],keep=\"first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Dans ce cas, on garde le premier. On peut demander à garder le dernier (last) et\n",
    "on utilisera des tris afin d’ordonner les résultats pour se débarrasser des duplications\n",
    "non pertinentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 Le traitement des données manquantes\n",
    "Les données manquantes sont un domaine de la data science à part entière. Leur traitement nécessite une réflexion bien au-delà de quelques lignes de codes.\n",
    "\n",
    "Dans tous vos projets data science, vous serez confronté à des données manquantes, deux startégies peuvent pricipalement être adoptées:\n",
    "- supprimer les données manquantes,\n",
    "- attribuer des valeurs à ces données manquantes, on parle de complétion. Nous présenterons quelques startégies Pour compléter les valeurs manquantes.\n",
    "\n",
    "**Remarque**: Lorsque vous importez des données avec Pandas, celui-ci va automatiquement\n",
    "remplacer les données manquantes par des codes nan. Pandas utilise le type np.nan de Numpy. Lors de l'application de fonctions sur une série (ex: la moyenne .mean()), les données manquantes sont ignorées. Cela évite des bugs mais cela peut-être trompeur également. On n'a pas forcément conscience qu'il nous manque des données à l'usage car on ne reçoit pas de message d'erreur\n",
    "\n",
    "#### La suppression des données manquantes\n",
    "L’approche la plus simple pour traiter des données manquantes est de supprimer les observations comportant des données manquantes.\n",
    "\n",
    "Pandas comporte de nombreuses méthodes pour cela. Si nous prenons les données sur les salaires des employés de la ville de Boston, nous pouvons utiliser :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# la table globale\n",
    "boston.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# la table lorsqu’on retire les lignes avec données manquantes\n",
    "boston.dropna().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# la table lorsqu’on retire les colonnes avec des données manquantes\n",
    "boston.dropna(axis = 1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit que dans cette table de nombreuses données manquantes existent surtout sur huit colonnes. Quatre colonnes sont complètes.\n",
    "\n",
    "#### La complétion par la moyenne, ou la médiane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il existe deux moyens de compléter des données par la moyenne ou par la médiane.\n",
    "\n",
    "Un premier en utilisant Pandas :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour la moyenne\n",
    "boston.INJURED= boston.INJURED.fillna(boston.INJURED.mean())     \n",
    "# pour la médiane\n",
    "boston.RETRO= boston.RETRO.fillna(boston.RETRO.median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le package Scikit-Learn permet aussi de faire des remplacements par la moyenne\n",
    "ou la médiane :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "# on crée un objet de cette classe avec la stratégie d’imputation comme\n",
    "# paramètre\n",
    "imputer = SimpleImputer(strategy = \"mean\")\n",
    "# on construit un nouveau jeu de données en appliquant la méthode\n",
    "# .fit_transform()\n",
    "boston_imputee= imputer.fit_transform(boston.select_dtypes(np.number))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.4 Le traitement des colonnes avec des données qualitatives\n",
    "Les données qualitatives sont extrêmement présentes dans les données. Dès que vous travaillez sur des données socio-démographiques sur des individus, vous allez rencontrer des données qualitatives. Le traitement des données qualitatives est souvent négligé dans les ouvrages de traitement de la donnée. Il est donc primordial de bien expliquer le traitement qu’elles requièrent.\n",
    "\n",
    "#### Le type categorical\n",
    "Les données qualitatives sont des valeurs textuelles par défaut. Pandas propose un type spécifique pour traiter ce type de données. Le type categorical permet d’optimiser le traitement de ce type de données.\n",
    "\n",
    "Il permet de créer et de transformer des données de ce type. Vous avez importé des données avec des variables qualitatives, Pandas va automatiquement les considérer comme du type object. Vous pourrez le voir en utilisant la propriété .dtype.\n",
    "Si vous désirez transformer ce type en un type categorical, vous pouvez utiliser la fonction pd.Categorical() :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_quali=pd.Categorical([\"Boston\",\"Paris\",\"Londres\",\"Paris\", \"Boston\"])\n",
    "var_quali.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### La transformation des données\n",
    "Pour traiter des données qualitatives, il faudra les transformer. \n",
    "\n",
    "En effet, les algorithmes que vous aurez à utiliser sont basés sur des données numériques et donc des variables quantitatives.\n",
    "\n",
    "Si vous travaillez sur des données nominales, il va falloir transformer les variables en indicatrices. C’est-à-dire que vous allez obtenir une colonne pour chaque modalité de votre variable qualitative.\n",
    "\n",
    "Cette approche peut être appliquée avec deux packages que nous utilisons souvent : Pandas et Scikit-Learn.\n",
    "\n",
    "Dans le cadre de nos données sur les logements AirBnB, nous avons plusieurs variables qualitatives, notamment roomtype qui a trois modalités :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing[\"room_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Approche Pandas avec get_dummies() :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_room_type = pd.get_dummies(listing[\"room_type\"])\n",
    "frame_room_type.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette fonction crée un nouveau DataFrame \n",
    "\n",
    "##### Approche Scikit-Learn avec OneHotEncoder() :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on importe la classe\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# on crée un objet de la classe OneHotEncoder\n",
    "encode=OneHotEncoder(sparse = False)\n",
    "# on l'applique directement sur la colonnes initiale\n",
    "array_out=encode.fit_transform(np.array(listing[\"room_type\"]).reshape(-1,1))\n",
    "# on transforme la sortie en DataFrame\n",
    "pd.DataFrame(array_out, columns=listing[\"room_type\"].unique()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.5 Les transformations numériques\n",
    "\n",
    "Lorsque vous travaillez sur des données, un certain nombre de transformations de base sont nécessaires. Deux packages pourront être utiles pour ce type de transformations : Scikit-Learn, Pandas.\n",
    "\n",
    "Avec Pandas, la plupart des transformations se font en faisant les calculs directement en utilisant les fonctions universelles de Pandas.\n",
    "\n",
    "Avec Scikit-Learn, l’approche est légèrement différente. Dans ce cas, on utilise des classes permettant de transformer les données.\n",
    "\n",
    "Nous utiliserons les données sur les employés de la ville de Boston desquelles nous extrayons les colonnes numériques :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_num=boston.select_dtypes(include=[np.number])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Centrer et réduire les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avec Pandas pour centrer et réduire\n",
    "boston_std=boston_num.apply(lambda x : (x-x.mean())/x.std())\n",
    "boston_std.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avec Scikit-Learn, on utilisera la classe StandardScaler :\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler(with_mean=True, with_std=True)\n",
    "rescaled=scaler.fit_transform(boston_num)\n",
    "pd.DataFrame(rescaled, index=boston_num.index, columns=boston_num.columns).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changer d’échelle\n",
    "\n",
    "On utilise pour passer à une échelle 0-100 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avec Pandas\n",
    "boston_0_100=boston_num.apply(lambda x : (x-x.min())/(x.max()-x.min())*100)\n",
    "boston_0_100.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avec Scikit-Learn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "minmaxscaler=MinMaxScaler((0,100))\n",
    "boston_0_100=minmaxscaler.fit_transform(boston_num)\n",
    "boston_0_100=pd.DataFrame(boston_0_100, index=boston_num.index, columns=boston_num.columns)\n",
    "boston_0_100.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Utilisation du groupby pour décrire des données\n",
    "\n",
    "#### Principe\n",
    "\n",
    "La méthode .groupby est une méthode qui permet de construire un objet à partir d’un DataFrame. Cet objet sépare les données en fonction des modalités d’une ou de plusieurs variables qualitatives. On obtiendra ainsi de manière quasi-immédiate des\n",
    "indicateurs par modalités. \n",
    "\n",
    "De nombreuses méthodes sont disponibles sur ces objets groupby afin de maximiser la simplicité de manipulation de données.\n",
    "Généralement, on suppose que le groupby est basé sur trois étapes : séparation/application et combinaison.\n",
    "\n",
    "Par exemple, sur les données AirBnB, on peut faire cela par type de chambres :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_group_room = listing.groupby(\"room_type\")\n",
    "listing_group_room[\"price\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On sépare et on calcule la moyenne, et on rassemble les résultats dans un nouvel objet. On affiche donc dans un objet Series les prix moyens par type de chambre. On voit ici qu’on a utilisé la méthode .mean() de la classe des objets groupby."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Opérations sur les objets groupby\n",
    "On peut très simplement obtenir des statistiques plus poussées avec des groupby.\n",
    "\n",
    "De nombreuses méthodes de transformation de données pourront être appliquées avec une étape .groupby()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply : une méthode importante pour manipuler vos groupby\n",
    "\n",
    "La méthode apply permet d’appliquer n’importe quelle fonction sur vos données.\n",
    "\n",
    "Si par exemple, vous désirez calculer l’écart salarial au sein de chaque département sur les données des salariés de la ville de Boston, vous allez devoir utiliser la différence entre le maximum et le minimum. Il n’existe pas de fonction universelle. \n",
    "\n",
    "Nous allons donc utiliser un groupby et la méthode apply :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_salaires_dep = boston.groupby('DEPARTMENT NAME')['TOTAL EARNINGS']\\\n",
    "                        .apply(lambda x : x.max()-x.min())\n",
    "diff_salaires_dep.sort_values(ascending = False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De nombreuses autres applications sont disponibles avec le groupby."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
