{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST en Deep Learning\n",
    "\n",
    "Dans ce TP, nous allons construire des algorithmes de Deep Learning pour tenter de reconnaître des chiffres manuscrits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données et transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons travailler sur la base de données MNIST qui contient 60000 images en niveaux de grille de résolution 28x28, représentant les 10 chiffres de 0 à 9, ainsi qu'un jeu de test de 10000 images. Tout d'abord, chargeons ce jeu de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "from tqdm import tqdm\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import scipy.ndimage\n",
    "import time\n",
    "import numpy as np\n",
    "from torchmetrics import Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chargement des données MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST('../data', train=True, transform=ToTensor())\n",
    "test_dataset = datasets.MNIST('../data', train=False, transform=ToTensor())\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    torch.cuda.set_device(0)\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer un dataloader et visualiser des images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH INFO : input shape:  torch.Size([16, 1, 28, 28])  , labels shape:  torch.Size([16]) \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=16)\n",
    "\n",
    "\n",
    "# Parcourez un batch dans le DataLoader\n",
    "for images, labels in train_dataloader:\n",
    "    print(\"BATCH INFO : input shape: \", images.shape, \" , labels shape: \", labels.shape, '\\n')\n",
    "    sample_images = images[:5]  # Les 5 premières images\n",
    "    sample_labels = labels[:5]  # Les 5 premières étiquettes\n",
    "    break  # On prend seulement le premier batch\n",
    "\n",
    "# Affichez les images et leurs étiquettes\n",
    "fig, axes = plt.subplots(1, 5, figsize=(12, 3))\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.imshow(\n",
    "        sample_images[i].squeeze(), cmap=\"gray\"\n",
    "    )  # .squeeze() pour retirer la dimension du canal\n",
    "    ax.set_title(f\"Label: {sample_labels[i].item()}\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construire un premier réseau de neurones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construisons notre premier réseau de neurones.\n",
    "\n",
    "Pour cela, nous allons créer un modèle Pytorch en utilisant la classe `nn.Module` vu précedemment.\n",
    "\n",
    "Puis utiliser les méthodes suivantes de Pytroch pour ajouter des couches à ce modèle :\n",
    "\n",
    "* `nn.FLatten` : on manipule des vecteurs et non des image, on passe de (28,28) -> (784,)\n",
    "* `nn.Linear` : on ajoute une couche dense (ou linéaire)\n",
    "* `nn.Dropout` : applique un dropout à la couche, pour éviter le surapprentissage\n",
    "* `nn.ReLU` : fonction d'activation relu au coeur du réseau\n",
    "* `nn.Softmax` : en sortie de réseau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "MyModel                                  [1, 10]                   --\n",
       "├─Flatten: 1-1                           [1, 784]                  --\n",
       "├─Linear: 1-2                            [1, 1024]                 803,840\n",
       "├─ReLU: 1-3                              [1, 1024]                 --\n",
       "├─Linear: 1-4                            [1, 512]                  524,800\n",
       "├─ReLU: 1-5                              [1, 512]                  --\n",
       "├─Linear: 1-6                            [1, 512]                  262,656\n",
       "├─ReLU: 1-7                              [1, 512]                  --\n",
       "├─Linear: 1-8                            [1, 10]                   5,130\n",
       "├─Softmax: 1-9                           [1, 10]                   --\n",
       "==========================================================================================\n",
       "Total params: 1,596,426\n",
       "Trainable params: 1,596,426\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 1.60\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.02\n",
       "Params size (MB): 6.39\n",
       "Estimated Total Size (MB): 6.41\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_classes = 10\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(784, 1024)  #\n",
    "        self.fc2 = nn.Linear(1024, 512)   \n",
    "        self.fc3 = nn.Linear(512, 512)   \n",
    "        self.fc4 = nn.Linear(512, nb_classes) \n",
    "        #self.dropout = nn.Dropout(0.5) # Couche de dropout\n",
    "        self.relu = nn.ReLU()    # Fonction d'activation sigmoïde\n",
    "        self.softmax = nn.Softmax(dim=1) # Fonction d'activation softmax\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc1(x)) # Activation sigmoid pour la première couche\n",
    "        x = self.relu(self.fc2(x)) # Activation sigmoid pour la deuxième couche\n",
    "        x = self.relu(self.fc3(x)) # Activation sigmoid pour la deuxième couche\n",
    "        #x = self.dropout(x)           # Dropout\n",
    "        x = self.softmax(self.fc4(x)) # Activation softmax pour la troisième couche\n",
    "        return x\n",
    "\n",
    "# Instanciation du modèle\n",
    "model = MyModel()\n",
    "\n",
    "# affichage du résumé du modèle\n",
    "summary(model, input_size=(1,1,28,28))  # input_size= (batch_size, channels, dim_x, dim_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " On commence par créer une boucle d'entrainement qui va faciliter l'apprentissage de notre modèle sur nos données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Défintion de la boucle d'entrainement\n",
    "def train_loop(\n",
    "    train_dataloader: torch.utils.data.DataLoader,\n",
    "    test_dataloader: torch.utils.data.DataLoader,\n",
    "    model: torch.nn.Module,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    epoch: int,\n",
    ")-> dict:\n",
    "    start_time = time.time()\n",
    "    # ICI\n",
    "    train_accuracy = Accuracy(task=\"multiclass\", num_classes=10).to(device)   # Définition de la métrique d'accuracy\n",
    "    model.to(device)\n",
    "    # Apprentissage du modèle\n",
    "    model.train()  # Met le modèle en mode entraînement\n",
    "    train_loss, count = 0.0, 0\n",
    "    for X, y in tqdm(train_dataloader, desc=f\"Train epoch {epoch}\"):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # Prédiction du réseau de neurones\n",
    "        y_hat = model(X).to(device)  \n",
    "        # calcul accuracy ICI\n",
    "        train_accuracy.update(y_hat.argmax(dim=-1), y)\n",
    "        # Calcul de l'erreur (y_hat, y)\n",
    "        loss = loss_fn(y_hat, y).to(device)   \n",
    "        # Backpropagation (MaJ des poids du réseau)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()        \n",
    "        train_loss += loss.item()\n",
    "        count += X.shape[0]\n",
    "    train_loss /= count\n",
    "\n",
    "    # Test du modèle\n",
    "    accuracy = Accuracy(task=\"multiclass\", num_classes=10).to(device)    # Définition de la métrique d'accuracy\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_loss, count = 0.0, 0\n",
    "        for X, y in tqdm(test_dataloader, desc=f\"Test epoch {epoch}\"):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            # Prédiction du réseau de neurones\n",
    "            y_hat = model(X)\n",
    "            # Calcul de l'erreur (y_hat, y)\n",
    "            loss = loss_fn(y_hat, y).to(device)   \n",
    "            test_loss += loss.item()\n",
    "\n",
    "            accuracy.update(y_hat.argmax(dim=-1), y)\n",
    "            count += X.shape[0]\n",
    "\n",
    "    test_loss /= count\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\n",
    "        f\"\"\"\n",
    "        --------------- Epoch {epoch} --------------- \n",
    "        Training Loss : {train_loss:.5f} | Training acc : {train_accuracy.compute():.2f} | Test Loss : {test_loss:.5f} | Test Accuracy : {accuracy.compute():.2f} | Elapsed Time : {round(elapsed_time, 1)}s\n",
    "        \"\"\"\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On redéfinit également les données nécessaires à l'apprentissage et au test en créant un itérateur (ou __dataloader__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite, nous pouvons lancer l'apprentissage des paramètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 0: 100%|██████████████████████████| 235/235 [00:04<00:00, 51.17it/s]\n",
      "Test epoch 0: 100%|█████████████████████████████| 40/40 [00:00<00:00, 56.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        --------------- Epoch 0 --------------- \n",
      "        Training Loss : 0.00576 | Training acc : 0.99 | Test Loss : 0.00592 | Test Accuracy : 0.98 | Elapsed Time : 5.3s\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 1: 100%|██████████████████████████| 235/235 [00:04<00:00, 52.03it/s]\n",
      "Test epoch 1: 100%|█████████████████████████████| 40/40 [00:00<00:00, 55.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        --------------- Epoch 1 --------------- \n",
      "        Training Loss : 0.00576 | Training acc : 0.99 | Test Loss : 0.00592 | Test Accuracy : 0.98 | Elapsed Time : 5.2s\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 2: 100%|██████████████████████████| 235/235 [00:04<00:00, 52.73it/s]\n",
      "Test epoch 2: 100%|█████████████████████████████| 40/40 [00:00<00:00, 58.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        --------------- Epoch 2 --------------- \n",
      "        Training Loss : 0.00576 | Training acc : 0.99 | Test Loss : 0.00592 | Test Accuracy : 0.98 | Elapsed Time : 5.1s\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 3: 100%|██████████████████████████| 235/235 [00:04<00:00, 52.03it/s]\n",
      "Test epoch 3: 100%|█████████████████████████████| 40/40 [00:00<00:00, 56.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        --------------- Epoch 3 --------------- \n",
      "        Training Loss : 0.00576 | Training acc : 0.99 | Test Loss : 0.00592 | Test Accuracy : 0.98 | Elapsed Time : 5.2s\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 4: 100%|██████████████████████████| 235/235 [00:04<00:00, 52.23it/s]\n",
      "Test epoch 4: 100%|█████████████████████████████| 40/40 [00:00<00:00, 55.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        --------------- Epoch 4 --------------- \n",
      "        Training Loss : 0.00576 | Training acc : 0.99 | Test Loss : 0.00592 | Test Accuracy : 0.98 | Elapsed Time : 5.2s\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 5: 100%|██████████████████████████| 235/235 [00:04<00:00, 52.73it/s]\n",
      "Test epoch 5: 100%|█████████████████████████████| 40/40 [00:00<00:00, 57.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        --------------- Epoch 5 --------------- \n",
      "        Training Loss : 0.00576 | Training acc : 0.99 | Test Loss : 0.00592 | Test Accuracy : 0.98 | Elapsed Time : 5.2s\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 6: 100%|██████████████████████████| 235/235 [00:04<00:00, 51.58it/s]\n",
      "Test epoch 6: 100%|█████████████████████████████| 40/40 [00:00<00:00, 55.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        --------------- Epoch 6 --------------- \n",
      "        Training Loss : 0.00576 | Training acc : 0.99 | Test Loss : 0.00592 | Test Accuracy : 0.98 | Elapsed Time : 5.3s\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 7: 100%|██████████████████████████| 235/235 [00:04<00:00, 51.72it/s]\n",
      "Test epoch 7: 100%|█████████████████████████████| 40/40 [00:00<00:00, 56.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        --------------- Epoch 7 --------------- \n",
      "        Training Loss : 0.00576 | Training acc : 0.99 | Test Loss : 0.00592 | Test Accuracy : 0.98 | Elapsed Time : 5.3s\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 8: 100%|██████████████████████████| 235/235 [00:04<00:00, 52.24it/s]\n",
      "Test epoch 8: 100%|█████████████████████████████| 40/40 [00:00<00:00, 57.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        --------------- Epoch 8 --------------- \n",
      "        Training Loss : 0.00576 | Training acc : 0.99 | Test Loss : 0.00592 | Test Accuracy : 0.98 | Elapsed Time : 5.2s\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 9: 100%|██████████████████████████| 235/235 [00:04<00:00, 51.58it/s]\n",
      "Test epoch 9: 100%|█████████████████████████████| 40/40 [00:00<00:00, 57.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        --------------- Epoch 9 --------------- \n",
      "        Training Loss : 0.00576 | Training acc : 0.99 | Test Loss : 0.00592 | Test Accuracy : 0.98 | Elapsed Time : 5.3s\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, nesterov=True)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
    "for epoch in range(epochs):\n",
    "    model = train_loop(train_dataloader, test_dataloader, model, loss_fn, optimizer, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous vous laissons analyser les résultats. Ce réseau de neurones est-il performant ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A vous de jouer__ : essayez de créer un meilleur réseau de neurones, afin d'atteindre le meilleur résultat possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "MyModel                                  [1, 10]                   --\n",
       "├─Flatten: 1-1                           [1, 784]                  --\n",
       "├─Linear: 1-2                            [1, 12]                   9,420\n",
       "├─ReLU: 1-3                              [1, 12]                   --\n",
       "├─Linear: 1-4                            [1, 12]                   156\n",
       "├─ReLU: 1-5                              [1, 12]                   --\n",
       "├─Dropout: 1-6                           [1, 12]                   --\n",
       "├─Linear: 1-7                            [1, 10]                   130\n",
       "├─Softmax: 1-8                           [1, 10]                   --\n",
       "==========================================================================================\n",
       "Total params: 9,706\n",
       "Trainable params: 9,706\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.01\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.04\n",
       "Estimated Total Size (MB): 0.04\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_classes = 10\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(784, 12)  # Première couche dense avec 784 entrées et 12 sorties\n",
    "        self.fc2 = nn.Linear(12, 12)   # Deuxième couche dense avec 12 entrées et 12 sorties\n",
    "        self.fc3 = nn.Linear(12, nb_classes) # Troisième couche dense avec 12 entrées et nb_classes sorties\n",
    "        self.dropout = nn.Dropout(0.5) # Couche de dropout\n",
    "        self.relu = nn.ReLU()    # Fonction d'activation sigmoïde\n",
    "        self.softmax = nn.Softmax(dim=1) # Fonction d'activation softmax\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc1(x)) # Activation sigmoid pour la première couche\n",
    "        x = self.relu(self.fc2(x)) # Activation sigmoid pour la deuxième couche\n",
    "        x = self.dropout(x)           # Dropout\n",
    "        x = self.softmax(self.fc3(x)) # Activation softmax pour la troisième couche\n",
    "        return x\n",
    "\n",
    "# Instanciation du modèle\n",
    "model = MyModel()\n",
    "\n",
    "# affichage du résumé du modèle\n",
    "summary(model, input_size=(1,1,28,28))  # input_size= (batch_size, channels, dim_x, dim_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 0: 100%|██████████████████████████| 235/235 [00:05<00:00, 44.01it/s]\n",
      "Test epoch 0: 100%|█████████████████████████████| 40/40 [00:00<00:00, 48.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        --------------- Epoch 0 --------------- \n",
      "        Training Loss : 0.00838 | Training acc : 0.30 | Test Loss : 0.00770 | Test Accuracy : 0.59 | Elapsed Time : 6.2s\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 1:  57%|██████████████▉           | 135/235 [00:03<00:02, 44.21it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m sgd_optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m, nesterov\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m----> 6\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msgd_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 17\u001b[0m, in \u001b[0;36mtrain_loop\u001b[0;34m(train_dataloader, test_dataloader, model, loss_fn, optimizer, epoch)\u001b[0m\n\u001b[1;32m     15\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()  \u001b[38;5;66;03m# Met le modèle en mode entraînement\u001b[39;00m\n\u001b[1;32m     16\u001b[0m train_loss, count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 17\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTrain epoch \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepoch\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Prédiction du réseau de neurones\u001b[39;49;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torchvision/datasets/mnist.py:143\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    139\u001b[0m img, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[index], \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargets[index])\n\u001b[1;32m    141\u001b[0m \u001b[38;5;66;03m# doing this so that it is consistent with all other datasets\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# to return a PIL Image\u001b[39;00m\n\u001b[0;32m--> 143\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mL\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(img)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/PIL/Image.py:3090\u001b[0m, in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   3088\u001b[0m shape \u001b[38;5;241m=\u001b[39m arr[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   3089\u001b[0m ndim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(shape)\n\u001b[0;32m-> 3090\u001b[0m strides \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrides\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   3091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3092\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "epochs = 10\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "sgd_optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, nesterov=True)\n",
    "for epoch in range(epochs):\n",
    "    model = train_loop(train_dataloader, test_dataloader, model, loss_fn, sgd_optimizer, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voyons ce que donne notre modèle sur un exemple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prediction(model, dataloader):\n",
    "    # Parcourez un batch dans le DataLoader\n",
    "    for images, labels in dataloader:\n",
    "        preds = model(images)\n",
    "        sample_images = images[:5]  # Les 5 premières images\n",
    "        sample_labels = labels[:5]  # Les 5 premières étiquettes\n",
    "        sample_preds = torch.argmax(preds[:5],dim=1)  # Les 5 premières predictions\n",
    "        break  # On prend seulement le premier batch\n",
    "    \n",
    "    # Affichez les images et leurs étiquettes\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(12, 3))\n",
    "    \n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.imshow(\n",
    "            sample_images[i].squeeze(), cmap=\"gray\"\n",
    "        )  # .squeeze() pour retirer la dimension du canal\n",
    "        ax.set_title(f\"Label: {sample_labels[i].item()}, Pred: {sample_preds[i].item()}\")\n",
    "        ax.axis(\"off\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_prediction(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN : réseaux de neurones convolutionnels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant implémenter un réseau de neurones convolutionnel.\n",
    "\n",
    "Pour cet exercice, vous allez avoir besoin des méthodes Pytorch suivantes, en plus de celles déjà vues précédemment :\n",
    "\n",
    "Construisons notre premier réseau de neurones.\n",
    "\n",
    "* `nn.Conv2d` : on ajoute une couche de convolution\n",
    "* `nn.MaxPool2d` : fonction de max pooling qui permet de réduire la dimension des images d'entrée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "MyCNNModel                               [1, 10]                   --\n",
       "├─Conv2d: 1-1                            [1, 4, 26, 26]            40\n",
       "├─ReLU: 1-2                              [1, 4, 26, 26]            --\n",
       "├─MaxPool2d: 1-3                         [1, 4, 13, 13]            --\n",
       "├─Flatten: 1-4                           [1, 676]                  --\n",
       "├─Linear: 1-5                            [1, 10]                   6,770\n",
       "├─ReLU: 1-6                              [1, 10]                   --\n",
       "├─Linear: 1-7                            [1, 10]                   110\n",
       "├─Softmax: 1-8                           [1, 10]                   --\n",
       "==========================================================================================\n",
       "Total params: 6,920\n",
       "Trainable params: 6,920\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.03\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.02\n",
       "Params size (MB): 0.03\n",
       "Estimated Total Size (MB): 0.05\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = (1, 1, 28, 28)\n",
    "nb_classes = 10\n",
    "# Définition du modèle\n",
    "class MyCNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=4, kernel_size=(3, 3))\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(4 * 13 * 13 , 10)\n",
    "        self.fc2 = nn.Linear(10, nb_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.soft = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.soft(self.fc2(x))\n",
    "        return x\n",
    "        \n",
    "# Instanciation du modèle\n",
    "cnn_model = MyCNNModel()\n",
    "\n",
    "# affichage du résumé du modèle\n",
    "summary(cnn_model, input_size=(1,1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 0: 100%|██████████████████████████| 235/235 [00:05<00:00, 45.78it/s]\n",
      "Test epoch 0: 100%|█████████████████████████████| 40/40 [00:00<00:00, 47.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        --------------- Epoch 0 --------------- \n",
      "        Training Loss : 0.00786 | Training acc : 0.45 | Test Loss : 0.00719 | Test Accuracy : 0.66 | Elapsed Time : 6.0s\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 1: 100%|██████████████████████████| 235/235 [00:05<00:00, 44.33it/s]\n",
      "Test epoch 1: 100%|█████████████████████████████| 40/40 [00:00<00:00, 41.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        --------------- Epoch 1 --------------- \n",
      "        Training Loss : 0.00703 | Training acc : 0.67 | Test Loss : 0.00718 | Test Accuracy : 0.67 | Elapsed Time : 6.3s\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 2: 100%|██████████████████████████| 235/235 [00:05<00:00, 41.51it/s]\n",
      "Test epoch 2: 100%|█████████████████████████████| 40/40 [00:00<00:00, 47.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        --------------- Epoch 2 --------------- \n",
      "        Training Loss : 0.00701 | Training acc : 0.67 | Test Loss : 0.00716 | Test Accuracy : 0.67 | Elapsed Time : 6.5s\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 3: 100%|██████████████████████████| 235/235 [00:05<00:00, 42.70it/s]\n",
      "Test epoch 3: 100%|█████████████████████████████| 40/40 [00:00<00:00, 47.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        --------------- Epoch 3 --------------- \n",
      "        Training Loss : 0.00700 | Training acc : 0.67 | Test Loss : 0.00715 | Test Accuracy : 0.67 | Elapsed Time : 6.3s\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 4: 100%|██████████████████████████| 235/235 [00:05<00:00, 39.84it/s]\n",
      "Test epoch 4: 100%|█████████████████████████████| 40/40 [00:01<00:00, 37.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        --------------- Epoch 4 --------------- \n",
      "        Training Loss : 0.00699 | Training acc : 0.67 | Test Loss : 0.00714 | Test Accuracy : 0.67 | Elapsed Time : 7.0s\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 5: 100%|██████████████████████████| 235/235 [00:05<00:00, 41.71it/s]\n",
      "Test epoch 5: 100%|█████████████████████████████| 40/40 [00:00<00:00, 46.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        --------------- Epoch 5 --------------- \n",
      "        Training Loss : 0.00698 | Training acc : 0.68 | Test Loss : 0.00714 | Test Accuracy : 0.67 | Elapsed Time : 6.5s\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 6: 100%|██████████████████████████| 235/235 [00:05<00:00, 43.09it/s]\n",
      "Test epoch 6: 100%|█████████████████████████████| 40/40 [00:01<00:00, 37.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        --------------- Epoch 6 --------------- \n",
      "        Training Loss : 0.00697 | Training acc : 0.68 | Test Loss : 0.00712 | Test Accuracy : 0.68 | Elapsed Time : 6.5s\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 7: 100%|██████████████████████████| 235/235 [00:05<00:00, 39.45it/s]\n",
      "Test epoch 7: 100%|█████████████████████████████| 40/40 [00:00<00:00, 55.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        --------------- Epoch 7 --------------- \n",
      "        Training Loss : 0.00696 | Training acc : 0.68 | Test Loss : 0.00712 | Test Accuracy : 0.68 | Elapsed Time : 6.7s\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 8: 100%|██████████████████████████| 235/235 [00:04<00:00, 51.64it/s]\n",
      "Test epoch 8: 100%|█████████████████████████████| 40/40 [00:00<00:00, 55.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        --------------- Epoch 8 --------------- \n",
      "        Training Loss : 0.00695 | Training acc : 0.68 | Test Loss : 0.00710 | Test Accuracy : 0.68 | Elapsed Time : 5.3s\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 9: 100%|██████████████████████████| 235/235 [00:04<00:00, 51.92it/s]\n",
      "Test epoch 9: 100%|█████████████████████████████| 40/40 [00:00<00:00, 48.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        --------------- Epoch 9 --------------- \n",
      "        Training Loss : 0.00694 | Training acc : 0.69 | Test Loss : 0.00709 | Test Accuracy : 0.69 | Elapsed Time : 5.4s\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "sgd_optimizer = optim.SGD(cnn_model.parameters(), lr=0.1, momentum=0.9, nesterov=True)\n",
    "for epoch in range(epochs):\n",
    "    cnn_model = train_loop(train_dataloader, test_dataloader, cnn_model, loss_fn, sgd_optimizer, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_prediction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[124], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplot_prediction\u001b[49m(cnn_model, test_dataloader)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_prediction' is not defined"
     ]
    }
   ],
   "source": [
    "plot_prediction(cnn_model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "MyCNNModel                               [1, 10]                   --\n",
       "├─Conv2d: 1-1                            [1, 32, 26, 26]           320\n",
       "├─ReLU: 1-2                              [1, 32, 26, 26]           --\n",
       "├─MaxPool2d: 1-3                         [1, 32, 13, 13]           --\n",
       "├─Conv2d: 1-4                            [1, 64, 11, 11]           18,496\n",
       "├─ReLU: 1-5                              [1, 64, 11, 11]           --\n",
       "├─MaxPool2d: 1-6                         [1, 64, 5, 5]             --\n",
       "├─Conv2d: 1-7                            [1, 64, 3, 3]             36,928\n",
       "├─ReLU: 1-8                              [1, 64, 3, 3]             --\n",
       "├─Flatten: 1-9                           [1, 576]                  --\n",
       "├─Linear: 1-10                           [1, 512]                  295,424\n",
       "├─ReLU: 1-11                             [1, 512]                  --\n",
       "├─Linear: 1-12                           [1, 128]                  65,664\n",
       "├─ReLU: 1-13                             [1, 128]                  --\n",
       "├─Linear: 1-14                           [1, 10]                   1,290\n",
       "├─Softmax: 1-15                          [1, 10]                   --\n",
       "==========================================================================================\n",
       "Total params: 418,122\n",
       "Trainable params: 418,122\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 3.15\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.24\n",
       "Params size (MB): 1.67\n",
       "Estimated Total Size (MB): 1.92\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = (1, 1, 28, 28)\n",
    "nb_classes = 10\n",
    "# Définition du modèle\n",
    "class MyCNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3, 3))\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3))\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3, 3))\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(576, 512)\n",
    "        self.fc2 = nn.Linear(512 , 128)\n",
    "        self.fc3 = nn.Linear(128, nb_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.softmax(self.fc3(x))\n",
    "        return x\n",
    "        \n",
    "# Instanciation du modèle\n",
    "cnn_model = MyCNNModel()\n",
    "\n",
    "# affichage du résumé du modèle\n",
    "summary(cnn_model, input_size=(1,1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 0: 100%|██████████████████████████| 235/235 [00:05<00:00, 46.20it/s]\n",
      "Test epoch 0: 100%|█████████████████████████████| 40/40 [00:00<00:00, 53.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        --------------- Epoch 0 --------------- \n",
      "        Training Loss : 0.00902 | Training acc : 0.10 | Test Loss : 0.00921 | Test Accuracy : 0.10 | Elapsed Time : 5.8s\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 1: 100%|██████████████████████████| 235/235 [00:05<00:00, 43.14it/s]\n",
      "Test epoch 1: 100%|█████████████████████████████| 40/40 [00:00<00:00, 52.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        --------------- Epoch 1 --------------- \n",
      "        Training Loss : 0.00902 | Training acc : 0.10 | Test Loss : 0.00921 | Test Accuracy : 0.10 | Elapsed Time : 6.2s\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 2: 100%|██████████████████████████| 235/235 [00:05<00:00, 46.62it/s]\n",
      "Test epoch 2: 100%|█████████████████████████████| 40/40 [00:00<00:00, 52.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        --------------- Epoch 2 --------------- \n",
      "        Training Loss : 0.00902 | Training acc : 0.10 | Test Loss : 0.00921 | Test Accuracy : 0.10 | Elapsed Time : 5.8s\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 3: 100%|██████████████████████████| 235/235 [00:05<00:00, 46.67it/s]\n",
      "Test epoch 3: 100%|█████████████████████████████| 40/40 [00:00<00:00, 55.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        --------------- Epoch 3 --------------- \n",
      "        Training Loss : 0.00902 | Training acc : 0.10 | Test Loss : 0.00921 | Test Accuracy : 0.10 | Elapsed Time : 5.8s\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 4:  52%|█████████████▍            | 122/235 [00:02<00:02, 46.73it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#sgd_optimizer = optim.SGD(cnn_model.parameters(), lr=0.01, momentum=0.9, nesterov=True)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m----> 6\u001b[0m     cnn_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcnn_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 17\u001b[0m, in \u001b[0;36mtrain_loop\u001b[0;34m(train_dataloader, test_dataloader, model, loss_fn, optimizer, epoch)\u001b[0m\n\u001b[1;32m     15\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()  \u001b[38;5;66;03m# Met le modèle en mode entraînement\u001b[39;00m\n\u001b[1;32m     16\u001b[0m train_loss, count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 17\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTrain epoch \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepoch\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Prédiction du réseau de neurones\u001b[39;49;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torchvision/datasets/mnist.py:146\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    143\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    149\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torchvision/transforms/transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[1;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torchvision/transforms/functional.py:176\u001b[0m, in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    174\u001b[0m img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mpermute((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, torch\u001b[38;5;241m.\u001b[39mByteTensor):\n\u001b[0;32m--> 176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_float_dtype\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.01)\n",
    "#sgd_optimizer = optim.SGD(cnn_model.parameters(), lr=0.01, momentum=0.9, nesterov=True)\n",
    "for epoch in range(epochs):\n",
    "    cnn_model = train_loop(train_dataloader, test_dataloader, cnn_model, loss_fn, optimizer, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
