{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST en Deep Learning\n",
    "\n",
    "Dans ce TP, nous allons construire des algorithmes de Deep Learning pour tenter de reconnaître des chiffres manuscrits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données et transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons travailler sur la base de données MNIST qui contient 60000 images en niveaux de grille de résolution 28x28, représentant les 10 chiffres de 0 à 9, ainsi qu'un jeu de test de 10000 images. Tout d'abord, chargeons ce jeu de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import scipy.ndimage\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "train_dataset = datasets.MNIST('../data', train=True, download=True, transform=ToTensor())\n",
    "#X_train_base, y_train_base = dataset_train.data.numpy(), dataset_train.target.numpy()\n",
    "\n",
    "test_dataset = datasets.MNIST('../data', train=False, download=True, transform=ToTensor())\n",
    "#X_test_base, y_test_base = dataset_test.data.numpy(), dataset_test.target.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer un dataloader et visualiser des images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH INFO : input shape:  torch.Size([16, 1, 28, 28])  , labels shape:  torch.Size([16]) \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=16)\n",
    "\n",
    "\n",
    "# Parcourez un batch dans le DataLoader\n",
    "for images, labels in train_dataloader:\n",
    "    print(\"BATCH INFO : input shape: \", images.shape, \" , labels shape: \", labels.shape, '\\n')\n",
    "    sample_images = images[:5]  # Les 5 premières images\n",
    "    sample_labels = labels[:5]  # Les 5 premières étiquettes\n",
    "    break  # On prend seulement le premier batch\n",
    "\n",
    "# Affichez les images et leurs étiquettes\n",
    "fig, axes = plt.subplots(1, 5, figsize=(12, 3))\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.imshow(\n",
    "        sample_images[i].squeeze(), cmap=\"gray\"\n",
    "    )  # .squeeze() pour retirer la dimension du canal\n",
    "    ax.set_title(f\"Label: {sample_labels[i].item()}\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construire un premier réseau de neurones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construisons notre premier réseau de neurones.\n",
    "\n",
    "Pour cela, nous allons créer un modèle Pytorch en utilisant la classe nn.Module vu précedemment:\n",
    "* __model = Sequential()__\n",
    "\n",
    "Puis utiliser les méthodes suivantes de Pytroch pour ajouter des couches à ce modèle :\n",
    "\n",
    "* __nn.FLatten__ : on manipule des vecteurs et non des image, on passe de (28,28) -> (784,)\n",
    "* __nn.Linear__ : on ajoute une couche dense (ou linéaire)\n",
    "* __nn.Dropout__ : applique un dropout à la couche, pour éviter le surapprentissage\n",
    "* __nn.ReLU__ : fonction d'activation relu au coeur du réseau\n",
    "* __nn.Softmax__ : en sortie de réseau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "MyModel                                  [256, 10]                 --\n",
       "├─Flatten: 1-1                           [256, 784]                --\n",
       "├─Linear: 1-2                            [256, 12]                 9,420\n",
       "├─ReLU: 1-3                              [256, 12]                 --\n",
       "├─Linear: 1-4                            [256, 12]                 156\n",
       "├─ReLU: 1-5                              [256, 12]                 --\n",
       "├─Dropout: 1-6                           [256, 12]                 --\n",
       "├─Linear: 1-7                            [256, 10]                 130\n",
       "├─Softmax: 1-8                           [256, 10]                 --\n",
       "==========================================================================================\n",
       "Total params: 9,706\n",
       "Trainable params: 9,706\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 2.48\n",
       "==========================================================================================\n",
       "Input size (MB): 0.80\n",
       "Forward/backward pass size (MB): 0.07\n",
       "Params size (MB): 0.04\n",
       "Estimated Total Size (MB): 0.91\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_classes = 10\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(784, 12)  # Première couche dense avec 784 entrées et 12 sorties\n",
    "        self.fc2 = nn.Linear(12, 12)   # Deuxième couche dense avec 12 entrées et 12 sorties\n",
    "        self.fc3 = nn.Linear(12, nb_classes) # Troisième couche dense avec 12 entrées et nb_classes sorties\n",
    "        self.dropout = nn.Dropout(0.5) # Couche de dropout\n",
    "        self.relu = nn.ReLU()    # Fonction d'activation sigmoïde\n",
    "        self.softmax = nn.Softmax(dim=1) # Fonction d'activation softmax\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc1(x)) # Activation sigmoid pour la première couche\n",
    "        x = self.relu(self.fc2(x)) # Activation sigmoid pour la deuxième couche\n",
    "        x = self.dropout(x)           # Dropout\n",
    "        x = self.softmax(self.fc3(x)) # Activation softmax pour la troisième couche\n",
    "        return x\n",
    "\n",
    "# Instanciation du modèle\n",
    "model = MyModel()\n",
    "\n",
    "# affichage du résumé du modèle\n",
    "summary(model, input_size=(1,1,28,28))  # input_size= (batch_size, channels, dim_x, dim_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " On commence par créer une boucle d'entrainement qui va faciliter l'apprentissage de notre modèle sur nos données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Défintion de la boucle d'entrainement\n",
    "def train_loop(\n",
    "    train_dataloader: torch.utils.data.DataLoader,\n",
    "    test_dataloader: torch.utils.data.DataLoader,\n",
    "    model: torch.nn.Module,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    epoch: int,\n",
    ")-> dict:\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Apprentissage du modèle\n",
    "    model.train()  # Met le modèle en mode entraînement\n",
    "    train_loss, count = 0.0, 0\n",
    "    for X, y in tqdm(train_dataloader, desc=f\"Train epoch {epoch}\"):\n",
    "        # Prédiction du réseau de neurones\n",
    "        y_hat = model(X)  \n",
    "        # Calcul de l'erreur (y_hat, y)\n",
    "        loss = loss_fn(y_hat, y)  \n",
    "        # Backpropagation (MaJ des poids du réseau)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        count += X.shape[0]\n",
    "    train_loss /= count\n",
    "\n",
    "    # Test du modèle\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_loss, count = 0.0, 0\n",
    "        for X, y in tqdm(test_dataloader, desc=f\"Test epoch {epoch}\"):\n",
    "            # Prédiction du réseau de neurones\n",
    "            y_hat = model(X)  \n",
    "            # Calcul de l'erreur (y_hat, y)\n",
    "            loss = loss_fn(y_hat, y)  \n",
    "            test_loss += loss.item()\n",
    "            count += X.shape[0]\n",
    "    test_loss /= count\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\n",
    "        f\"Epoch {epoch} | Elapsed Time : {round(elapsed_time, 1)}s | Training Loss : {train_loss:.4f} | Test Loss : {test_loss:.4f}\"\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On redéfinit également les données nécessaires à l'apprentissage et au test en créant un itérateur (ou __dataloader__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(train_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite, nous pouvons lancer l'apprentissage des paramètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 0: 100%|██████████████████████████| 235/235 [00:18<00:00, 12.77it/s]\n",
      "Test epoch 0: 100%|███████████████████████████| 235/235 [00:05<00:00, 44.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Elapsed Time : 23.6s | Training Loss : 0.0074 | Test Loss : 0.0065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 1: 100%|██████████████████████████| 235/235 [00:05<00:00, 42.83it/s]\n",
      "Test epoch 1: 100%|███████████████████████████| 235/235 [00:04<00:00, 47.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Elapsed Time : 10.4s | Training Loss : 0.0072 | Test Loss : 0.0064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs=2\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "sgd_optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, nesterov=True)\n",
    "for epoch in range(epochs):\n",
    "    model = train_loop(train_dataloader, test_dataloader, model, loss_fn, sgd_optimizer, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous vous laissons analyser les résultats. Ce réseau de neurones est-il performant ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A vous de jouer__ : essayez de créer un meilleur réseau de neurones, afin d'atteindre le meilleur résultat possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un meilleur réseau de neurones, et l'entraîner\n",
    "# Objectif : avoir le meilleur résultat possible\n",
    "\n",
    "# Nous ne donnons pas la correction. Il y a plusieurs réponses possibles.\n",
    "# Vous pouvez par exemple ajouter des couches, modifier le nombre de neurones par couche et jouer sur le dropout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voyons ce que donne notre modèle sur un exemple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mnist_digit(image):\n",
    "    \"\"\" Plot a single MNIST image.\"\"\"\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(image, cmap = matplotlib.cm.binary)\n",
    "    plt.xticks(np.array([]))\n",
    "    plt.yticks(np.array([]))\n",
    "    plt.show()\n",
    "loss,acc = model.evaluate(X_test, y_test,  verbose=0)\n",
    "index=800\n",
    "print('The accuracy on the test set is ',(acc*100),'%')\n",
    "plot_mnist_digit(X_test_base[index])\n",
    "#cl=model.predict_classes(X_test[index].reshape((1,784)))\n",
    "cl = np.argmax(model.predict(X_test[index].reshape((1,784))), axis=-1)\n",
    "\n",
    "print(\"le chiffre reconnu est: \", cl[0])\n",
    "print(\"le chiffre à reconnaitre  est: \", np.argmax(y_test[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN : réseaux de neurones convolutionnels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant implémenter un réseau de neurones convolutionnel.\n",
    "\n",
    "Pour cet exercice, vous allez avoir besoin des méthodes Pytorch suivantes, en plus de celles déjà vues précédemment :\n",
    "\n",
    "Construisons notre premier réseau de neurones.\n",
    "\n",
    "* __nn.Conv2d__ : on ajoute une couche de convolution\n",
    "* __nn.MaxPool2d__ : fonction de max pooling qui permet de réduire la dimension des images d'entrée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "MyModel                                  [1, 10]                   110\n",
       "├─Conv2d: 1-1                            [1, 4, 26, 26]            40\n",
       "├─ReLU: 1-2                              [1, 4, 26, 26]            --\n",
       "├─MaxPool2d: 1-3                         [1, 4, 13, 13]            --\n",
       "├─Dropout2d: 1-4                         [1, 4, 13, 13]            --\n",
       "├─Flatten: 1-5                           [1, 676]                  --\n",
       "├─Linear: 1-6                            [1, 10]                   6,770\n",
       "├─ReLU: 1-7                              [1, 10]                   --\n",
       "├─Dropout: 1-8                           [1, 10]                   --\n",
       "==========================================================================================\n",
       "Total params: 6,920\n",
       "Trainable params: 6,920\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.03\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.02\n",
       "Params size (MB): 0.03\n",
       "Estimated Total Size (MB): 0.05\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = (1, 1, 28, 28)\n",
    "nb_classes = 10\n",
    "# Définition du modèle\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=4, kernel_size=(3, 3))\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(4 * 13 * 13 , 10)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(10, nb_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout2(x)\n",
    "        #x = self.fc2(x)\n",
    "        return x\n",
    "        \n",
    "# Instanciation du modèle\n",
    "model = MyModel()\n",
    "\n",
    "# affichage du résumé du modèle\n",
    "batch_size = 256\n",
    "summary(model, input_size=(1,1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 0: 100%|██████████████████████████| 235/235 [00:07<00:00, 30.36it/s]\n",
      "Test epoch 0: 100%|███████████████████████████| 235/235 [00:10<00:00, 21.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Elapsed Time : 18.6s | Training Loss : 0.0091 | Test Loss : 0.0090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 1: 100%|██████████████████████████| 235/235 [00:18<00:00, 12.84it/s]\n",
      "Test epoch 1: 100%|███████████████████████████| 235/235 [00:16<00:00, 14.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Elapsed Time : 34.7s | Training Loss : 0.0091 | Test Loss : 0.0090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 2: 100%|██████████████████████████| 235/235 [00:48<00:00,  4.81it/s]\n",
      "Test epoch 2: 100%|███████████████████████████| 235/235 [00:16<00:00, 13.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Elapsed Time : 65.8s | Training Loss : 0.0091 | Test Loss : 0.0090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 3: 100%|██████████████████████████| 235/235 [00:49<00:00,  4.77it/s]\n",
      "Test epoch 3: 100%|███████████████████████████| 235/235 [00:16<00:00, 14.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Elapsed Time : 65.7s | Training Loss : 0.0091 | Test Loss : 0.0090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 4: 100%|██████████████████████████| 235/235 [00:48<00:00,  4.80it/s]\n",
      "Test epoch 4: 100%|███████████████████████████| 235/235 [00:16<00:00, 14.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Elapsed Time : 65.4s | Training Loss : 0.0091 | Test Loss : 0.0090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 5: 100%|██████████████████████████| 235/235 [00:48<00:00,  4.85it/s]\n",
      "Test epoch 5: 100%|███████████████████████████| 235/235 [00:16<00:00, 14.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Elapsed Time : 64.9s | Training Loss : 0.0091 | Test Loss : 0.0090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 6: 100%|██████████████████████████| 235/235 [00:47<00:00,  4.94it/s]\n",
      "Test epoch 6: 100%|███████████████████████████| 235/235 [00:15<00:00, 15.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | Elapsed Time : 62.7s | Training Loss : 0.0091 | Test Loss : 0.0090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 7: 100%|██████████████████████████| 235/235 [00:47<00:00,  4.96it/s]\n",
      "Test epoch 7: 100%|███████████████████████████| 235/235 [00:15<00:00, 15.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | Elapsed Time : 62.5s | Training Loss : 0.0091 | Test Loss : 0.0090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 8: 100%|██████████████████████████| 235/235 [00:44<00:00,  5.23it/s]\n",
      "Test epoch 8: 100%|███████████████████████████| 235/235 [00:15<00:00, 14.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | Elapsed Time : 60.8s | Training Loss : 0.0091 | Test Loss : 0.0090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 9: 100%|██████████████████████████| 235/235 [00:09<00:00, 24.73it/s]\n",
      "Test epoch 9: 100%|███████████████████████████| 235/235 [00:05<00:00, 40.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 | Elapsed Time : 15.3s | Training Loss : 0.0091 | Test Loss : 0.0090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 10: 100%|█████████████████████████| 235/235 [00:11<00:00, 20.72it/s]\n",
      "Test epoch 10: 100%|██████████████████████████| 235/235 [00:05<00:00, 42.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Elapsed Time : 16.9s | Training Loss : 0.0091 | Test Loss : 0.0090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 11: 100%|█████████████████████████| 235/235 [00:07<00:00, 32.70it/s]\n",
      "Test epoch 11: 100%|██████████████████████████| 235/235 [00:05<00:00, 39.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Elapsed Time : 13.1s | Training Loss : 0.0091 | Test Loss : 0.0090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 12: 100%|█████████████████████████| 235/235 [00:11<00:00, 20.81it/s]\n",
      "Test epoch 12: 100%|██████████████████████████| 235/235 [00:08<00:00, 27.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Elapsed Time : 19.7s | Training Loss : 0.0091 | Test Loss : 0.0090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 13: 100%|█████████████████████████| 235/235 [00:07<00:00, 33.57it/s]\n",
      "Test epoch 13: 100%|██████████████████████████| 235/235 [00:05<00:00, 43.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Elapsed Time : 12.4s | Training Loss : 0.0091 | Test Loss : 0.0090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 14: 100%|█████████████████████████| 235/235 [00:07<00:00, 30.73it/s]\n",
      "Test epoch 14: 100%|██████████████████████████| 235/235 [00:06<00:00, 35.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Elapsed Time : 14.2s | Training Loss : 0.0091 | Test Loss : 0.0090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 15: 100%|█████████████████████████| 235/235 [00:06<00:00, 33.94it/s]\n",
      "Test epoch 15: 100%|██████████████████████████| 235/235 [00:05<00:00, 41.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Elapsed Time : 12.6s | Training Loss : 0.0091 | Test Loss : 0.0090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 16: 100%|█████████████████████████| 235/235 [00:06<00:00, 36.13it/s]\n",
      "Test epoch 16: 100%|██████████████████████████| 235/235 [00:06<00:00, 38.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Elapsed Time : 12.6s | Training Loss : 0.0091 | Test Loss : 0.0090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 17: 100%|█████████████████████████| 235/235 [00:09<00:00, 24.44it/s]\n",
      "Test epoch 17: 100%|██████████████████████████| 235/235 [00:05<00:00, 43.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Elapsed Time : 15.0s | Training Loss : 0.0091 | Test Loss : 0.0090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 18: 100%|█████████████████████████| 235/235 [00:06<00:00, 35.37it/s]\n",
      "Test epoch 18: 100%|██████████████████████████| 235/235 [00:05<00:00, 41.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Elapsed Time : 12.3s | Training Loss : 0.0091 | Test Loss : 0.0090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 19: 100%|█████████████████████████| 235/235 [00:09<00:00, 24.41it/s]\n",
      "Test epoch 19: 100%|██████████████████████████| 235/235 [00:13<00:00, 16.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Elapsed Time : 23.5s | Training Loss : 0.0091 | Test Loss : 0.0090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs=20\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "adam_optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "for epoch in range(epochs):\n",
    "    model = train_loop(train_dataloader, test_dataloader, model, loss_fn, sgd_optimizer, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mnist_digit(image):\n",
    "    \"\"\" Plot a single MNIST image.\"\"\"\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(image, cmap = matplotlib.cm.binary)\n",
    "    plt.xticks(np.array([]))\n",
    "    plt.yticks(np.array([]))\n",
    "    plt.show()\n",
    "#loss,acc = model.evaluate(x_test, y_test,  verbose=0)\n",
    "#index=800\n",
    "#print('The accuracy on the test set is ',(acc*100),'%')\n",
    "#plot_mnist_digit(X_test_base[index])\n",
    "#cl=model.predict_classes(x_test[index].reshape((1,28,28,1)))\n",
    "#cl = np.argmax(model.predict(X_test[index].reshape((1,28,28,1))), axis=-1)\n",
    "\n",
    "\n",
    "print(\"le chiffre reconnu est: \", cl[0])\n",
    "print(\"le chiffre à reconnaitre  est: \", np.argmax(y_test[index]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un meilleur réseau de neurones convolutionnel, et l'entraîner\n",
    "# Objectif : avoir le meilleur résultat possible\n",
    "\n",
    "# Nous ne donnons pas la correction. Il y a plusieurs réponses possibles.\n",
    "# Vous pouvez par exemple ajouter des couches convolutionnelles et max_pooling,\n",
    "# modifier le nombre de convolutions ou leur taille et jouer sur le dropout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus : Auto encodeur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'auto-encodeur est un réseau de neurones qui compresse puis décompresse l'information. On l'entraîne en lui demandant de retrouver en sortie la même image que celle qu'il avait en entrée. Ici, l'information en entrée est en dimension 784 (28x28), et l'auto-encodeur va la compresser en dimension 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_dim = 2\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(encoding_dim, input_shape=(784,),activation='relu'))\n",
    "\n",
    "model.add(Dense(784, activation='sigmoid'))\n",
    "\n",
    "# Définition du modèle\n",
    "class MyAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        slef.flatten()\n",
    "        # Couche d'encodage\n",
    "        self.encoder = nn.Linear(input_shape, encoding_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Couche de décodage\n",
    "        self.decoder = nn.Linear(encoding_dim, 784)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encodage\n",
    "        x = self.relu(self.encoder(x))\n",
    "\n",
    "        # Décodage\n",
    "        x = self.sigmoid(self.decoder(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "model= MyAutoencoder()\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichons quelques images pour voir comment se comporte notre auto-encodeur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(X_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "__A vous de jouer__ : essayez d'améliorer l'auto-encodeur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## A COMPLETER\n",
    "\n",
    "# Nous ne donnons pas la correction. Il y a plusieurs réponses possibles.\n",
    "# Vous pouvez par exemple ajouter des couches ou modifier le nombre de neurones de la couche cachée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
